{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca66425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 20:28:09.156580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 20:28:09.924782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-09-07 20:28:09.924864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-09-07 20:28:09.924872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "directory for the model already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 20:28:11.093901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 20:28:11.892803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19590 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 6)]    0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, None, 1)     0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, None)        0           ['tf.__operators__.getitem[0][0]'\n",
      " icingOpLambda)                                                  ]                                \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, None)         0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, None, 8)      960         ['input_1[0][0]',                \n",
      "                                                                  'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, 8)     32          ['bidirectional[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, None, 8)      0           ['batch_normalization[0][0]',    \n",
      "                                                                  'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, None, 32)     2080        ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " p_re_lu (PReLU)                (None, None, 32)     32          ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, None, 32)    0           ['p_re_lu[0][0]',                \n",
      " )                                                                'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, 32)    128         ['tf.math.multiply_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, None, 32)     2080        ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, None, 32)     8224        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " p_re_lu_2 (PReLU)              (None, None, 32)     32          ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " p_re_lu_1 (PReLU)              (None, None, 32)     32          ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, None, 1)      0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, 32)    128         ['p_re_lu_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, None, 32)    0           ['p_re_lu_1[0][0]',              \n",
      " )                                                                'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, None, 32)    128         ['batch_normalization_3[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, 32)    128         ['tf.math.multiply_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, None, 32)    0           ['batch_normalization_4[0][0]',  \n",
      " )                                                                'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 64)     0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'tf.math.multiply_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, None, 32)     32800       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " p_re_lu_3 (PReLU)              (None, None, 32)     32          ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, None, 32)    0           ['p_re_lu_3[0][0]',              \n",
      " )                                                                'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, None, 32)    128         ['tf.math.multiply_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, None, 32)     32800       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, None, 32)     16416       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " p_re_lu_5 (PReLU)              (None, None, 32)     32          ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " p_re_lu_4 (PReLU)              (None, None, 32)     32          ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, None, 1)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, None, 32)    128         ['p_re_lu_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, None, 32)    0           ['p_re_lu_4[0][0]',              \n",
      " )                                                                'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, None, 32)    128         ['batch_normalization_7[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, None, 32)    128         ['tf.math.multiply_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, None, 32)    0           ['batch_normalization_8[0][0]',  \n",
      " )                                                                'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, None, 64)     0           ['batch_normalization_6[0][0]',  \n",
      "                                                                  'tf.math.multiply_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, None, 32)     40992       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " p_re_lu_6 (PReLU)              (None, None, 32)     32          ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, None, 32)    0           ['p_re_lu_6[0][0]',              \n",
      " )                                                                'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, None, 32)    128         ['tf.math.multiply_7[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, None, 32)     40992       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, None, 32)     20512       ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " p_re_lu_8 (PReLU)              (None, None, 32)     32          ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " p_re_lu_7 (PReLU)              (None, None, 32)     32          ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, None, 1)     0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, None, 32)    128         ['p_re_lu_8[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, None, 32)    0           ['p_re_lu_7[0][0]',              \n",
      " )                                                                'max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, None, 32)    128         ['batch_normalization_11[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, None, 32)    128         ['tf.math.multiply_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, None, 32)    0           ['batch_normalization_12[0][0]', \n",
      " )                                                                'max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, None)        0           ['max_pooling1d_2[0][0]']        \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, None, 64)     0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'tf.math.multiply_9[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, None)         0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 16)          10368       ['concatenate_2[0][0]',          \n",
      " )                                                                'tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16)          64          ['bidirectional_1[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            34          ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 210,178\n",
      "Trainable params: 209,362\n",
      "Non-trainable params: 816\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "21703\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 20:28:29.455148: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_22/output/_17'\n",
      "2023-09-07 20:28:30.280628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-09-07 20:28:31.345438: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-07 20:28:32.932150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-07 20:28:32.940587: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f77640489a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-07 20:28:32.940621: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-09-07 20:28:32.948893: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-07 20:28:33.031225: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-07 20:28:33.084217: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21703/21703 [==============================] - ETA: 0s - loss: 0.0480 - E_0.5: 0.9300 - 1-S_0.5: 0.9923 - E_0.9: 0.6254 - 1-S_0.9: 0.9998 - accuracy: 0.9555\n",
      "Epoch 1: val_1-S_0.5 improved from -inf to 0.99795, saving model to ../models/nn_1LSTM_3RB_1LSTM_tuned1/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_1LSTM_3RB_1LSTM_tuned1/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_1LSTM_3RB_1LSTM_tuned1/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21703/21703 [==============================] - 4418s 202ms/step - loss: 0.0480 - E_0.5: 0.9300 - 1-S_0.5: 0.9923 - E_0.9: 0.6254 - 1-S_0.9: 0.9998 - accuracy: 0.9555 - val_loss: 0.0425 - val_E_0.5: 0.8934 - val_1-S_0.5: 0.9980 - val_E_0.9: 0.5498 - val_1-S_0.9: 1.0000 - val_accuracy: 0.9449\n",
      "Epoch 2/10\n",
      "21703/21703 [==============================] - ETA: 0s - loss: 0.0378 - E_0.5: 0.9459 - 1-S_0.5: 0.9938 - E_0.9: 0.6984 - 1-S_0.9: 0.9999 - accuracy: 0.9655\n",
      "Epoch 2: val_1-S_0.5 improved from 0.99795 to 0.99799, saving model to ../models/nn_1LSTM_3RB_1LSTM_tuned1/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_1LSTM_3RB_1LSTM_tuned1/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_1LSTM_3RB_1LSTM_tuned1/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21703/21703 [==============================] - 2221s 102ms/step - loss: 0.0378 - E_0.5: 0.9459 - 1-S_0.5: 0.9938 - E_0.9: 0.6984 - 1-S_0.9: 0.9999 - accuracy: 0.9655 - val_loss: 0.0387 - val_E_0.5: 0.9011 - val_1-S_0.5: 0.9980 - val_E_0.9: 0.6372 - val_1-S_0.9: 1.0000 - val_accuracy: 0.9488\n",
      "Epoch 3/10\n",
      "21703/21703 [==============================] - ETA: 0s - loss: 0.0347 - E_0.5: 0.9498 - 1-S_0.5: 0.9943 - E_0.9: 0.7285 - 1-S_0.9: 0.9999 - accuracy: 0.9680\n",
      "Epoch 3: val_1-S_0.5 improved from 0.99799 to 0.99830, saving model to ../models/nn_1LSTM_3RB_1LSTM_tuned1/best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_1LSTM_3RB_1LSTM_tuned1/best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_1LSTM_3RB_1LSTM_tuned1/best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21703/21703 [==============================] - 2221s 102ms/step - loss: 0.0347 - E_0.5: 0.9498 - 1-S_0.5: 0.9943 - E_0.9: 0.7285 - 1-S_0.9: 0.9999 - accuracy: 0.9680 - val_loss: 0.0388 - val_E_0.5: 0.8904 - val_1-S_0.5: 0.9983 - val_E_0.9: 0.6436 - val_1-S_0.9: 1.0000 - val_accuracy: 0.9435\n",
      "Epoch 4/10\n",
      "21703/21703 [==============================] - ETA: 0s - loss: 0.0325 - E_0.5: 0.9523 - 1-S_0.5: 0.9948 - E_0.9: 0.7498 - 1-S_0.9: 0.9999 - accuracy: 0.9697\n",
      "Epoch 4: val_1-S_0.5 did not improve from 0.99830\n",
      "21703/21703 [==============================] - 2188s 101ms/step - loss: 0.0325 - E_0.5: 0.9523 - 1-S_0.5: 0.9948 - E_0.9: 0.7498 - 1-S_0.9: 0.9999 - accuracy: 0.9697 - val_loss: 0.0373 - val_E_0.5: 0.8924 - val_1-S_0.5: 0.9981 - val_E_0.9: 0.6857 - val_1-S_0.9: 1.0000 - val_accuracy: 0.9445\n",
      "Epoch 5/10\n",
      " 6538/21703 [========>.....................] - ETA: 24:50 - loss: 0.0333 - E_0.5: 0.9493 - 1-S_0.5: 0.9947 - E_0.9: 0.7492 - 1-S_0.9: 0.9999 - accuracy: 0.9683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18384/21703 [========================>.....] - ETA: 5:31 - loss: 0.0314 - E_0.5: 0.9575 - 1-S_0.5: 0.9942 - E_0.9: 0.7702 - 1-S_0.9: 0.9999 - accuracy: 0.9709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8955/21703 [===========>..................] - ETA: 21:05 - loss: 0.0316 - E_0.5: 0.9535 - 1-S_0.5: 0.9948 - E_0.9: 0.7615 - 1-S_0.9: 0.9999 - accuracy: 0.9700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20808/21703 [===========================>..] - ETA: 1:28 - loss: 0.0297 - E_0.5: 0.9570 - 1-S_0.5: 0.9951 - E_0.9: 0.7759 - 1-S_0.9: 0.9999 - accuracy: 0.9722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11408/21703 [==============>...............] - ETA: 17:09 - loss: 0.0298 - E_0.5: 0.9589 - 1-S_0.5: 0.9946 - E_0.9: 0.7830 - 1-S_0.9: 0.9999 - accuracy: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21703/21703 [==============================] - ETA: 0s - loss: 0.0287 - E_0.5: 0.9573 - 1-S_0.5: 0.9955 - E_0.9: 0.7843 - 1-S_0.9: 0.9999 - accuracy: 0.9729\n",
      "Epoch 7: val_1-S_0.5 did not improve from 0.99830\n",
      "21703/21703 [==============================] - 2192s 101ms/step - loss: 0.0287 - E_0.5: 0.9573 - 1-S_0.5: 0.9955 - E_0.9: 0.7843 - 1-S_0.9: 0.9999 - accuracy: 0.9729 - val_loss: 0.0567 - val_E_0.5: 0.8628 - val_1-S_0.5: 0.9978 - val_E_0.9: 0.6664 - val_1-S_0.9: 1.0000 - val_accuracy: 0.9293\n",
      "Epoch 8/10\n",
      " 1975/21703 [=>............................] - ETA: 32:57 - loss: 0.0301 - E_0.5: 0.9577 - 1-S_0.5: 0.9948 - E_0.9: 0.7629 - 1-S_0.9: 0.9999 - accuracy: 0.9716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11409/21703 [==============>...............] - ETA: 17:15 - loss: 0.0289 - E_0.5: 0.9601 - 1-S_0.5: 0.9949 - E_0.9: 0.7905 - 1-S_0.9: 0.9999 - accuracy: 0.9728"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# scripts for NN\n",
    "import sys\n",
    "sys.path.append('./nn_builds')\n",
    "from nn import *\n",
    "from train import train_model, make_train_figs\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "# GPU on\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# data and model's names\n",
    "name = 'baikal_multi_0523_flat_pureMC_h5s2_norm.h5'\n",
    "path_to_h5 = '../data/' + name\n",
    "mn = 'nn_1LSTM_3RB_1LSTM_tuned1'\n",
    "model_name = mn\n",
    "\n",
    "# making dir for model if necessary\n",
    "try:\n",
    "    os.makedirs('../models/'+model_name)\n",
    "    print('directory for the model is created')\n",
    "except:\n",
    "    print('directory for the model already exists')\n",
    "\n",
    "# getting the shape of data\n",
    "Shape = (None, 6)\n",
    "            \n",
    "# set hyperparams\n",
    "lr_initial = 0.005 #tuned\n",
    "batch_size = 256\n",
    "# making model\n",
    "model = globals()[mn](Shape)\n",
    "print(model.summary())\n",
    "\n",
    "# training model and creating figs\n",
    "history = train_model(model, path_to_h5, batch_size, lr_initial, model_name, shape = Shape, \n",
    "                      num_of_epochs = 10, verbose = 1)\n",
    "make_train_figs(history, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844b832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
