{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cdc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 09:42:12.256011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-16 09:42:13.027548: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-06-16 09:42:13.027625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/:/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-06-16 09:42:13.027633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2721e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mult noise\n",
    "class gauss_mult_noise:\n",
    "    def __init__(self, Q_mean_noise, n_fraction):\n",
    "        self.Q_mean_noise = Q_mean_noise\n",
    "        self.n_fraction = n_fraction\n",
    "    def make_noise(self, Qs, mask):\n",
    "        noises = np.random.normal( scale=self.n_fraction, size=Qs.shape )*mask\n",
    "        Qs = Qs + (Qs+self.Q_mean_noise)*noises\n",
    "        return Qs\n",
    "\n",
    "# addative noise\n",
    "def add_gauss(data_in, g_add_stds):\n",
    "    data = data_in[:,:,:-1]\n",
    "    mask = data_in[:,:,-1:]\n",
    "    g_add_stds = np.broadcast_to(g_add_stds, data.shape)\n",
    "    noise = np.random.normal( scale=g_add_stds, size=data.shape )*mask\n",
    "    data += noise\n",
    "    sort_idxs = np.argsort(data[:,:,1:2], axis=1)\n",
    "    data = np.take_along_axis( data, sort_idxs, axis=1)\n",
    "    data = np.concatenate((data,mask), axis=-1)\n",
    "    return data\n",
    "\n",
    "def add_gauss(data_in, g_add_stds):\n",
    "    data = data_in[:,:,:-1]\n",
    "    mask = data_in[:,:,-1:]\n",
    "    g_add_stds = np.broadcast_to(g_add_stds, data.shape)\n",
    "    noise = np.random.normal( scale=g_add_stds, size=data.shape )*mask\n",
    "    data += noise\n",
    "    sort_idxs = np.argsort(data[:,:,1:2], axis=1)\n",
    "    data = np.take_along_axis( data, sort_idxs, axis=1)\n",
    "    data = np.concatenate((data,mask), axis=-1)\n",
    "    return data\n",
    "\n",
    "class generator:\n",
    "    def __init__(self, file, regime, batch_size, w_mu, w_nu, \n",
    "                 set_up_Q_lim, up_Q_lim, set_low_Q_lim, low_Q_lim, \n",
    "                 apply_add_gauss, g_add_stds, apply_mult_gauss, q_noise_fraction, is_mask = True):\n",
    "        self.file = file\n",
    "        self.regime = regime\n",
    "        self.batch_size = batch_size\n",
    "        with h5.File(self.file, 'r') as hf:\n",
    "            self.num = hf[self.regime + '/data/data'].shape[0]\n",
    "            self.batch_num = self.num // self.batch_size\n",
    "            self.gen_num = self.batch_num * self.batch_size\n",
    "            self.w_mu = w_mu\n",
    "            self.w_nu = w_nu\n",
    "\n",
    "            #For noise\n",
    "            self.set_up_Q_lim = set_up_Q_lim\n",
    "            self.set_low_Q_lim = set_low_Q_lim\n",
    "            self.is_mask = is_mask\n",
    "            self.apply_add_gauss = apply_add_gauss\n",
    "            self.apply_mult_gauss = apply_mult_gauss\n",
    "            self.g_add_stds = g_add_stds\n",
    "            if set_up_Q_lim:\n",
    "                Q_mean = hf['norm_param/mean'][0]\n",
    "                Q_std = hf['norm_param/std'][0]\n",
    "                self.Q_up_lim_norm = (up_Q_lim-Q_mean)/Q_std\n",
    "            if set_low_Q_lim:\n",
    "                self.means = hf['norm_param/mean'][()]\n",
    "                self.stds = hf['norm_param/std'][()]\n",
    "                self.Q_low_lim_norm = (low_Q_lim-self.means[0])/self.stds[0]\n",
    "                self.aux_idxs = hf['aux_mask/idxs'][()]\n",
    "                self.aux_vals = hf['aux_mask/vals'][()]\n",
    "            if apply_mult_gauss:\n",
    "                Q_mean = hf['norm_param/mean'][0]\n",
    "                Q_std = hf['norm_param/std'][0]\n",
    "                self.mult_gauss = gauss_mult_noise(Q_mean/Q_std, q_noise_fraction)\n",
    "            self.batch_num = self.num // self.batch_size\n",
    "        \n",
    "    def step(self, start, stop):\n",
    "        with h5.File(self.file, 'r') as hf:\n",
    "            data = hf[self.regime + '/data/data'][start:stop]\n",
    "            if self.is_mask:\n",
    "                mask = hf[self.regime + '/mask/data'][start:stop]\n",
    "                mask = np.expand_dims(mask,axis = -1)\n",
    "                data = np.concatenate((data,mask),axis = -1)\n",
    "            labels = np.zeros((self.batch_size, 2))\n",
    "            ids = hf[self.regime + '/ev_ids/data'][start:stop]  # id of event - starting with 'nu' or 'mu'\n",
    "            ids = np.array([i[0] for i in ids]).reshape(ids.shape[0],1)\n",
    "            labels[:] = np.where(ids == 110, [0,1], [1,0])  # 110 - byte code for letter 'n'\n",
    "            weights = np.where(labels[..., 0] == 1, self.w_mu, self.w_nu)\n",
    "            if self.set_up_Q_lim:\n",
    "                data[:,:,0:1] = np.where( data[:,:,0:1]*mask>self.Q_up_lim_norm, self.Q_up_lim_norm, data[:,:,0:1] )\n",
    "            # apply noise\n",
    "            if self.apply_add_gauss:\n",
    "                data = add_gauss(data, self.g_add_stds)\n",
    "            if self.apply_mult_gauss:\n",
    "                data[:,:,0] = self.mult_gauss.make_noise(data[:,:,0], data[:,:,-1])\n",
    "            return (data, labels, weights)\n",
    "        \n",
    "    def __call__(self):\n",
    "        start = 0\n",
    "        stop = self.batch_size\n",
    "        for i in range(self.batch_num):\n",
    "            out_data = self.step(start,stop)\n",
    "            yield out_data\n",
    "            start+=self.batch_size\n",
    "            stop+=self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02cea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is mask\n",
    "is_mask = True\n",
    "\n",
    "# gauss noise\n",
    "# 0.1 ~ 1 p.e., 150 ns, 4, 4, 15 m\n",
    "apply_add_gauss = True\n",
    "# normal\n",
    "g_add_stds = [0.03, 0.005, 0.005, 0.005, 0.00003]\n",
    "# bigger\n",
    "#stds_gauss = [0.03, 0.005, 0.02, 0.02, 0.0007]\n",
    "apply_mult_gauss = True\n",
    "q_noise_fraction = 0.1\n",
    "\n",
    "# limiting Q vals\n",
    "set_up_Q_lim = True\n",
    "up_Q_lim = 100\n",
    "set_low_Q_lim= False\n",
    "low_Q_lim = 0.\n",
    "\n",
    "name = 'baikal_mu-nu_h5-s2_tres08_old_norm.h5'\n",
    "h5f = '../../../../../ivkhar/Baikal/data/' + name\n",
    "gen = generator(h5f, 'val', 10, 1, 1, \n",
    "                             set_up_Q_lim, up_Q_lim, set_low_Q_lim, low_Q_lim, \n",
    "                             apply_add_gauss, g_add_stds, apply_mult_gauss, q_noise_fraction, is_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e98b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File(h5f, 'r') as hf:\n",
    "    data = hf['val/data/data'][0:20]\n",
    "data_noise = next(gen())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3591ffd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7334568 , 0.8396493 , 0.94570625, 1.0519007 , 1.1579926 ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_noise[0,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "542dbc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73344314, 0.83958685, 0.94573843, 1.0518894 , 1.1579981 ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        , 3.        , 3.        , 3.        , 3.        ,\n",
       "       3.        ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4fb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
