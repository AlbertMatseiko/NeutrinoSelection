{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefbddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./scripts')\n",
    "from nn import nn2\n",
    "from train import train_model, make_train_figs\n",
    "\n",
    "# GPU on\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8e9418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 25) (None, 25, 64)\n"
     ]
    }
   ],
   "source": [
    "Shape = (100,3)\n",
    "model = nn2(Shape, is_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3754d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 100, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 100, 128)     12416       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " p_re_lu_2 (PReLU)              (None, 100, 128)     128         ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 100, 1)      0           ['input_2[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 100, 128)    0           ['p_re_lu_2[0][0]',              \n",
      " )                                                                'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 100, 128)    512         ['tf.math.multiply_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 50, 128)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 50, 64)       65600       ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " p_re_lu_3 (PReLU)              (None, 50, 64)       64          ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 50, 1)       0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 50, 64)      0           ['p_re_lu_3[0][0]',              \n",
      " )                                                                'max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 25, 1)       0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 50, 64)      256         ['tf.math.multiply_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 25)          0           ['max_pooling1d_7[0][0]']        \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 25, 64)      0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 25)           0           ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 25, 32)      24832       ['max_pooling1d_6[0][0]',        \n",
      " )                                                                'tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 32)      128         ['bidirectional_7[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25, 2)        66          ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 104,002\n",
      "Trainable params: 103,554\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e304012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 1) (2, 5, 3)\n",
      "(2, 5, 1) (2, 5, 3)\n",
      "tf.Tensor(\n",
      "[[[ 4.31624358e-04  1.14983774e-03  1.36700657e-03  3.30452994e-03\n",
      "    1.88302263e-04 -5.93915058e-04 -9.34389609e-05 -6.59035053e-04\n",
      "   -3.78206227e-04  5.76371152e-04  3.86828469e-04  5.49790217e-04\n",
      "   -2.90619140e-03  1.32648228e-03 -1.28905894e-03  3.94236937e-04\n",
      "    2.40742695e-03 -2.81129760e-04 -1.62886386e-03 -2.89454794e-04\n",
      "    1.77813548e-04  1.68447004e-04  9.95579394e-05 -4.39112727e-03\n",
      "    4.70328559e-05 -4.71946078e-05  8.90783151e-04 -1.55128902e-04\n",
      "    3.34389129e-04  2.30547297e-03 -5.55412436e-04  1.08611025e-03\n",
      "   -1.94954197e-03  1.00053090e-03 -8.41965884e-05 -1.74288312e-03\n",
      "   -2.59779254e-03 -9.81485471e-04 -1.24209240e-04 -9.52250339e-05\n",
      "   -1.02406763e-03 -1.50901615e-03 -1.17131078e-03  3.39742110e-04\n",
      "   -7.95863976e-04 -3.77641176e-04 -1.37924962e-03 -8.72826087e-04\n",
      "   -5.39326167e-04 -2.39818532e-04 -6.15702651e-04 -4.24558093e-04\n",
      "   -5.89544594e-04  4.72704269e-04  4.76979039e-04  3.33207194e-04\n",
      "    1.22970610e-04  5.93584497e-04 -6.65025727e-05  1.53078046e-03\n",
      "   -2.23179857e-04 -1.21012714e-03  1.20407021e-05  9.26508394e-04]\n",
      "  [ 1.03531318e-04  6.22681808e-04  5.31432976e-04  2.99582118e-03\n",
      "    6.87626773e-04 -7.31550332e-04  1.63300894e-04  2.87141156e-04\n",
      "   -3.77447141e-04  3.36996338e-04  3.14108125e-04  1.83958991e-03\n",
      "   -2.63524312e-03  1.06573373e-03 -6.24065637e-04  1.90247991e-03\n",
      "    1.86738360e-03  9.19644081e-05 -2.08080327e-03 -3.86911815e-05\n",
      "    2.24493770e-03  1.90125022e-04 -6.55010168e-04 -4.31637373e-03\n",
      "   -1.15728959e-04 -1.77364680e-04  2.39447636e-05 -2.99319800e-04\n",
      "    1.13985101e-04  1.01078150e-03 -1.18311576e-03  5.46960277e-04\n",
      "   -1.69845601e-03 -6.21853047e-04 -2.19628011e-04 -6.90481043e-04\n",
      "   -2.85234489e-03 -8.07554228e-04 -3.04098823e-04 -1.75346126e-04\n",
      "   -7.40666117e-04 -1.61900895e-03 -4.64906829e-04  1.01762079e-03\n",
      "   -4.10331675e-04 -2.17757479e-04 -1.31668290e-03 -1.54111895e-03\n",
      "   -3.85126827e-04 -2.84914975e-04 -3.32369760e-04 -6.40166108e-05\n",
      "   -2.47116055e-04  4.84000921e-04 -6.64512697e-07  1.23780489e-03\n",
      "    8.14343919e-04  1.42617340e-04 -2.11269034e-05  1.80621713e-03\n",
      "   -1.19116216e-04 -3.05582798e-04 -1.74955894e-05  9.05354740e-04]\n",
      "  [ 6.70270529e-05  4.87240293e-04  8.76895327e-04  2.10137316e-03\n",
      "    3.39029590e-04 -3.99183074e-04  1.15523224e-04 -8.87552960e-06\n",
      "   -2.76901788e-04  4.72100859e-04  4.28521918e-04  9.58071672e-04\n",
      "   -2.15211255e-03  4.81599971e-04 -5.31268073e-04  1.02839980e-03\n",
      "    1.57082360e-03  1.36046947e-04 -1.27489772e-03 -1.48223960e-04\n",
      "    1.04101200e-03  1.34373267e-05  7.69811013e-05 -2.65349797e-03\n",
      "   -7.25064865e-06 -1.40845717e-04  2.68651085e-04 -7.35838548e-05\n",
      "    1.98520254e-04  1.30906096e-03 -7.69352133e-04 -2.56209823e-05\n",
      "   -1.29929697e-03 -1.56909911e-04  7.31627515e-05 -8.59092223e-04\n",
      "   -2.00198102e-03 -9.62146616e-04 -1.98100359e-04  3.75692849e-04\n",
      "   -1.53825473e-04 -6.63132814e-04 -9.21505445e-04  8.34199076e-04\n",
      "    7.08635635e-05 -3.25099943e-04 -7.27360835e-04 -5.41801623e-04\n",
      "   -2.70011195e-04 -2.36815395e-04 -2.67196272e-04 -4.55436588e-04\n",
      "   -1.24447717e-04  2.22033370e-04  1.01949445e-04 -1.16975862e-04\n",
      "    3.95138952e-04 -1.06060188e-05  4.53347056e-05  7.85083103e-04\n",
      "   -2.78091698e-04 -2.57935812e-04  9.33296833e-05  1.14887056e-03]\n",
      "  [ 8.16550455e-05  7.48466002e-04  5.39915753e-04  3.08719161e-03\n",
      "    9.42885235e-04 -8.09658435e-04  4.77472611e-04  3.22119013e-04\n",
      "   -3.72615788e-04  4.62785043e-04  5.63458249e-04  2.13452172e-03\n",
      "   -2.70397449e-03  6.50817878e-04 -2.43621878e-04  2.02252483e-03\n",
      "    2.04524631e-03  4.02369013e-04 -2.05827295e-03 -5.13492232e-05\n",
      "    2.39655352e-03  4.62937256e-04 -4.11952758e-04 -3.30059696e-03\n",
      "   -1.02944396e-04 -1.69651699e-04  5.64637739e-05 -5.21254144e-04\n",
      "   -9.41567669e-06  1.40900828e-03 -1.26031053e-03 -1.18881624e-04\n",
      "   -1.63577613e-03 -1.10717479e-03 -4.84757125e-04 -5.72313264e-04\n",
      "   -2.27934262e-03 -1.23180600e-03 -3.78123426e-04  8.70612857e-04\n",
      "   -1.75998823e-04 -1.11442548e-03 -3.57740326e-04  1.07559515e-03\n",
      "   -6.17617934e-06 -5.64739225e-04 -1.16944010e-03 -1.53441413e-03\n",
      "   -5.10518905e-04 -2.47234013e-04 -4.54937603e-04 -6.08904447e-05\n",
      "   -1.36183837e-04  7.03926547e-04 -1.86133020e-05  2.33079263e-04\n",
      "    7.35865673e-04 -1.12788846e-04 -2.15027991e-04  1.90136058e-03\n",
      "   -1.69794555e-04 -1.90060236e-04 -1.03901955e-04  1.17158063e-03]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 6.21833664e-04  4.51688888e-04  1.50287093e-03  3.73727246e-03\n",
      "    2.63892318e-04 -9.30010865e-04 -1.48262188e-05  7.30943866e-05\n",
      "   -4.27896768e-04  4.55162255e-04  8.28665099e-04  7.86801626e-04\n",
      "   -4.00137994e-03  1.00964867e-03 -1.80523156e-03  1.70970312e-03\n",
      "    2.91411323e-03  1.09417315e-05 -1.87229598e-03 -4.84490651e-04\n",
      "    1.06521731e-03 -1.83438475e-04  8.54683924e-04 -4.86259023e-03\n",
      "    9.30419628e-06 -2.68808333e-04  1.30395207e-03  5.16148102e-05\n",
      "    7.12251232e-04  3.30345053e-03 -9.10135102e-04  6.67632325e-04\n",
      "   -2.31544697e-03  6.63380779e-05  2.64500355e-04 -1.28933100e-03\n",
      "   -2.31172051e-03 -7.75203924e-04 -1.28733576e-04  3.46009008e-04\n",
      "   -7.30188622e-04 -4.49608517e-04 -2.38472736e-03  9.38019133e-04\n",
      "    1.24516635e-04 -9.74666968e-04 -7.68802362e-04 -1.36100152e-03\n",
      "   -4.86063946e-04 -3.55058437e-04 -7.99420464e-04 -1.10822055e-03\n",
      "   -3.81334830e-04  4.16084746e-04  2.95545789e-04 -8.17073509e-04\n",
      "    2.06171651e-04  2.47754098e-04  3.90728790e-04  1.10686407e-03\n",
      "   -5.10824204e-04 -1.19854556e-03  1.48566076e-04  1.76328386e-03]\n",
      "  [ 6.67195418e-04  4.32561559e-04  2.71587586e-03  4.08251351e-03\n",
      "    2.38924520e-04 -7.58641458e-04  1.57567792e-05 -4.10933222e-04\n",
      "   -5.35286032e-04  8.01120012e-04  1.54143211e-03  8.15913721e-04\n",
      "   -4.25217859e-03  5.44566195e-04 -1.16947608e-03  1.34012580e-03\n",
      "    3.38574359e-03  3.40701314e-04 -2.09361082e-03 -6.08788803e-04\n",
      "    8.25075491e-04 -1.83352997e-04  1.12160516e-03 -3.93288210e-03\n",
      "    5.46878709e-06  1.91258106e-04  1.39724731e-03  6.21034938e-04\n",
      "    8.49366770e-04  3.90412286e-03 -1.04597677e-03 -1.38884658e-04\n",
      "   -2.79346877e-03  5.97135186e-05  1.18001954e-04 -1.94346521e-03\n",
      "   -1.91833486e-03 -1.52031018e-03 -2.36109176e-04  1.46954833e-03\n",
      "   -3.26157351e-05 -2.07171237e-04 -2.92936387e-03  1.49801362e-03\n",
      "    9.57851240e-04 -1.46990956e-03 -5.69566619e-04 -9.13096708e-04\n",
      "   -3.64622014e-04 -3.36135301e-04 -1.10804592e-03 -2.26327172e-03\n",
      "   -2.05198696e-04  3.06768256e-04  8.31030542e-04 -1.51455961e-03\n",
      "    2.79976957e-04  6.64347754e-05 -3.72002651e-05  7.99640839e-04\n",
      "   -6.91469526e-04 -1.00109936e-03  2.30607926e-04  2.56411824e-03]\n",
      "  [ 2.82292545e-04  9.01484746e-04  5.35024272e-04  2.34688143e-03\n",
      "    2.20372385e-04 -7.79124617e-04  2.65793878e-05 -1.17655989e-04\n",
      "   -2.04091863e-04  1.81976313e-04  5.38677152e-04  5.72789053e-04\n",
      "   -2.47513526e-03  7.57621368e-04 -4.41400334e-04  8.80102976e-04\n",
      "    1.56116614e-03  2.45557807e-04 -1.31619419e-03 -1.99913338e-04\n",
      "    5.90561831e-04 -1.75698879e-04  1.54673922e-04 -2.31819670e-03\n",
      "   -1.54765530e-05 -2.34435447e-05  9.41616541e-04 -3.50990624e-04\n",
      "   -1.69302130e-05  1.41704571e-03 -6.02912740e-04 -1.51330445e-04\n",
      "   -1.51096750e-03 -1.04639403e-04  6.54172982e-05 -7.61465169e-04\n",
      "   -1.43228786e-03 -7.01106153e-04 -1.13970484e-04  7.39811047e-04\n",
      "   -1.77520298e-04 -4.78894362e-04 -6.54565229e-04  8.25712777e-05\n",
      "   -4.16669325e-04 -6.90234418e-04 -9.72017995e-04 -3.89001245e-04\n",
      "   -3.96080519e-04 -1.10795256e-04 -6.61796774e-04 -6.56344928e-05\n",
      "   -2.46061507e-04  4.95266286e-04  1.58778261e-04 -8.54169630e-05\n",
      "   -7.32172630e-05  1.94250063e-07  6.40517974e-05  9.98871983e-04\n",
      "   -2.68309726e-04 -6.44448563e-04 -1.48584568e-05  1.02030230e-03]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]], shape=(2, 5, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nn_constructor import *\n",
    "b = bidir_class(64, True, act = 'tanh', rec_act = 'sigmoid', merge_mode = 'mul')\n",
    "x = np.random.uniform(size = (2,5,3))\n",
    "mask = np.expand_dims(np.array([[1,1,1,1,0],[1,1,1,0,0]]), axis = -1)\n",
    "print(mask.shape,x.shape)\n",
    "print(b.block(x, mask_lstm = tf.cast(mask, bool))*mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9a6408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1688d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 13:32:00.155265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 13:32:03.761985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11209 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./scripts')\n",
    "from ds_making import *\n",
    "\n",
    "is_mask = True\n",
    "batch_size = 256\n",
    "file_name = \"baikal_mu-nu_h5-s2_tres08_old_norm.h5\"\n",
    "path_to_h5 = '../../../../ivkhar/Baikal/data/' + file_name\n",
    "\n",
    "with h5.File(path_to_h5, 'r') as hf:\n",
    "        total_num = hf['train/data/data'].shape[0]\n",
    "        steps_per_epoch = (total_num // batch_size) // 1\n",
    "        Shape = hf['train/data/data'].shape[1:]\n",
    "        #Учёт маски\n",
    "        if is_mask:\n",
    "            Shape = list(Shape)\n",
    "            Shape[1] += 1\n",
    "            Shape = tuple(Shape)\n",
    "\n",
    "\n",
    "train_dataset = make_train_dataset(path_to_h5, batch_size, Shape, is_mask = is_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f35fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 256, 96, 6), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "636c65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import h5py as h5\n",
    "sys.path.append('./scripts')\n",
    "from ds_making import make_train_dataset, make_test_dataset, make_datasets_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48c782fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"baikal_mu-nu_h5-s2_tres08_old_norm.h5\"\n",
    "path_to_h5 = '../../../../ivkhar/Baikal/data/' + file_name\n",
    "batch_size = 256\n",
    "### getting the shape of data\n",
    "with h5.File(path_to_h5, 'r') as hf:\n",
    "    Shape = hf['test/data/data'].shape[1:]\n",
    "    Shape = tuple([None,Shape[1]+1])\n",
    "    pure_data = hf['test/data/data'][0:256]\n",
    "test_dataset = make_test_dataset(path_to_h5, batch_size, Shape, is_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca48b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = next(test_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23e128ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.5174608 ,  1.5073937 ,  1.0566024 ,  1.0578704 ,  1.0630524 ,\n",
       "         1.0621067 , -0.12455566, -0.1331442 ,  3.        ,  3.        ],\n",
       "       dtype=float32),\n",
       " array([ 1.5139594,  1.5139594,  1.0626556,  1.0626556,  1.0626556,\n",
       "         1.0626556, -0.1293371, -0.1293371,  3.       ,  3.       ],\n",
       "       dtype=float32),\n",
       " array([ 0.00350142, -0.00656569, -0.00605321, -0.00478518,  0.00039685,\n",
       "        -0.00054884,  0.00478144, -0.0038071 ,  0.        ,  0.        ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = el[0][0:10,:,:-1]-pure_data[0:10]\n",
    "n = 2\n",
    "c = 3\n",
    "el[0][n,0:10,c], pure_data[n,0:10,c], delta[n,0:10,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a444706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 20:38:00.931910: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 20:38:01.889358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-09-05 20:38:01.889446: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/albert/miniconda3/envs/Baikal2/lib/\n",
      "2023-09-05 20:38:01.889456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from scripts.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ff86e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.9\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "str = '3 товара за 200.99'\n",
    "pat = r'\\d+.\\d'\n",
    "match = re.search(pat,str)\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb389ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
